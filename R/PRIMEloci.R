#' Run a Python Script for Profile Prediction
#'
#' This function runs a specified Python script using the `reticulate` package.
#'
#' @param script_path Character. The path to the Python script to be executed.
#' @param script_dir Character. The directory where the Python script resides.
#' @param profile_main_dir Character.
#' The main directory containing profile data.
#' @param profile_sub_dir Character.
#' The subdirectory within the main profile directory.
#' @param model_path Character.
#' The path to the trained model file to be used for prediction.
#' @param name_prefix Character.
#' A prefix to be added to the output files generated by the Python script.
#' @param threshold Numeric.
#' The probability threshold for classifying predictions. Default is 0.5.
#' @param file_format Character.
#' The format of the profile files (e.g., "parquet", "csv").
#' Default is "parquet".
#'
#' @return None. This function is used for its side effects of
#' running the Python script.
#'
#' @details
#' The function first checks if the specified Python script exists.
#' If the script exists, it constructs a command string to pass
#' the required arguments and runs the script using `reticulate::py_run_string`.
#' The command includes various parameters like the working directory,
#' profile directories, model path,
#' output name prefix, classification threshold, and file format.
#'
#' If the script does not exist, the function stops and throws an error message.
#'
#' @importFrom reticulate py_run_string
#'
#' @examples
#' \dontrun{
#' run_prediction_python_script(
#'   script_path = "path/to/predict_profile_probabilities.py",
#'   script_dir = "path/to/scripts",
#'   profile_main_dir = "path/to/profiles/main",
#'   profile_sub_dir = "subdir_name",
#'   model_path = "path/to/model.h5",
#'   name_prefix = "output_prefix",
#'   threshold = 0.7,
#'   file_format = "parquet"
#' )
#' }
#'
run_prediction_python_script <- function(script_path,
                                         script_dir,
                                         profile_main_dir,
                                         profile_sub_dir,
                                         model_path, name_prefix,
                                         threshold = 0.5,
                                         file_format = "parquet") {
  # Check if the script exists
  if (file.exists(script_path)) {
    # Create a Python command with the required arguments
    command <- sprintf(
      "import sys; sys.argv = ['%s', '-w', '%s', '-p', '%s', '-r', '%s', '-m', '%s', '-n', '%s', '-t', '%f', '-f', '%s']; exec(open('%s').read())", # nolint: line_length_linter.
      script_path, script_dir, profile_main_dir, profile_sub_dir, model_path, name_prefix, threshold, file_format, script_path # nolint: line_length_linter.
    )

    # Run the Python script with arguments
    reticulate::py_run_string(command)
  } else {
    stop("The specified script does not exist.")
  }
}

#' Process All Prediction Files
#'
#' This function processes all files matching
#' a specified pattern in a given directory.
#' It reads each file, applies the `wrapup_filter_bed_to_reduce` function
#' from the `PRIMEloci` package,
#' and stores the results in a `GRangesList`.
#'
#' @param prediction_dir Character.
#' The directory where the prediction files are located.
#' @param partial_name Character.
#' A pattern to match files in the `prediction_dir`.
#'
#' @return A `GRangesList` object containing the processed results
#' from all matching files.
#'
#' @details
#' The function lists all files in the specified directory
#' that match the given pattern.
#' For each file, it applies the `wrapup_filter_bed_to_reduce` function
#' and stores the result in a `GRangesList` object.
#' If no files are found matching the pattern, the function stops
#' and throws an error.
#'
#' @importFrom GenomicRanges GRangesList
#' @importFrom tools file_path_sans_ext
#'
#' @examples
#' \dontrun{
#' gr_list <- process_all_files(
#'   prediction_dir = "path/to/predictions",
#'   partial_name = "pattern_to_match"
#' )
#' }
#'
process_all_files <- function(prediction_dir, partial_name) {
  # List all files matching the partial name in the specified directory
  files <- list.files(path = prediction_dir,
                      pattern = partial_name,
                      full.names = TRUE)

  if (length(files) == 0) {
    stop("No files found matching the pattern in the specified directory.")
  }

  gr_list <- GenomicRanges::GRangesList()  # Initialize an empty GRangesList

  for (file in files) {
    writeLines(paste("Processing", file, "..."))

    # Call wrapup_filter_bed_to_reduce
    # and store the returned GRanges in the list
    gr <- wrapup_filter_bed_to_reduce(file, prediction_dir)

    # Extract the base name of the file without the extension to use as the name
    file_name <- tools::file_path_sans_ext(basename(file))

    # Add the GRanges object to the GRangesList with the file name as the name
    gr_list[[file_name]] <- gr
  }

  # Return the combined GRangesList with names
  return(gr_list)
}


#' Get tag clusters and extend from thick positions
#'
#' This function calculates tag clusters from
#' a RangedSummarizedExperiment object \code{ctss_rse}
#' and extends them by a specified distance \code{ext_dis}
#' around the thick positions.
#'
#' @param ctss_rse A RangedSummarizedExperiment object containing CAGE data.
#' @param ext_dis An integer specifying the distance
#' to extend around thick positions (default is 200).
#'
#' @return A GenomicRanges::GRangesList object where each element corresponds to
#'         a tag cluster extended by \code{ext_dis} around the thick positions.
#'
#' @details
#' The function iterates over columns of \code{ctss_rse},
#' calculates pooled counts,
#' subsets clusters based on a score threshold (> 0),
#' and clusters them unidirectionally.
#' It then extends each cluster by \code{ext_dis} base pairs
#' around the thick positions
#' and stores the results in a GRangesList object.
#'
#' @import SummarizedExperiment
#' @import GenomicRanges
#' @import IRanges
#' @import CAGEfightR
#' @import assertthat
#' @examples
#' # Example usage with a RangedSummarizedExperiment object
#' # ctss_rse <- ...  # Load or create your RangedSummarizedExperiment object
#' # ext_dis <- 200   # Define your extension distance
#' # result <- get_tagclusters_and_extend_fromthick(ctss_rse, ext_dis)
#'
#' @export
get_tcs_and_extend_fromthick <- function(ctss_rse, ext_dis = 200) {
  # Assert that ctss_rse is a RangedSummarizedExperiment object
  assertthat::assert_that(
    inherits(ctss_rse, "RangedSummarizedExperiment"),
    msg = "ctss_rse must be a RangedSummarizedExperiment object."
  )

  # Assert that ext_dis is an integer
  assertthat::assert_that(
    ext_dis == round(ext_dis),
    msg = "ext_dis must be an integer."
  )

  # Get column names
  col_ctss_rse <- colnames(ctss_rse)

  # Initialize GRangesList
  tc_grl <- GenomicRanges::GRangesList()

  # Loop over column names
  for (i in col_ctss_rse) {

    writeLines(paste("Processing: ", i, "\n"))

    # Extract data for current column
    ctss <- ctss_rse[, i]

    # Calculate pooled counts
    ctss <- CAGEfightR::calcPooled(ctss, inputAssay = "counts")

    # Subset by score > 0 (score column is created by calcPooled())
    ctss <- base::subset(ctss, score > 0)

    # Cluster unidirectionally
    object <- CAGEfightR::clusterUnidirectionally(ctss)

    # Create new ranges around thick positions
    new_ranges <- IRanges::IRanges(start = start(object$thick) - ext_dis,
                                   end = end(object$thick) + ext_dis)

    # Assign new ranges to object
    new_object <- object
    IRanges::ranges(new_object) <- new_ranges

    # Trim new object
    writeLines("Trimming out-of-bound ranges...")
    new_object <- GenomicRanges::trim(new_object)

    writeLines("Keep only prefered width...\n")
    len_vec <- ext_dis * 2 + 1

    new_object_widths <- GenomicRanges::width(new_object)
    new_object <- new_object[new_object_widths == len_vec]

    # Store in GRangesList
    tc_grl[[i]] <- new_object
  }

  return(tc_grl)
}



#' Convert Row Name Strands to No-strand
#'
#' This function converts the strand information
#' in row names from "+" or "-" to "*".
#'
#' @param strand_str A character vector of row names
#' containing strand information.
#' @return A character vector with strand information converted to "*".
#'
convert_rowname_to_nostrand <- function(strand_str) {
  strand_str <- gsub("[+-]$", "*", strand_str)
  return(strand_str)
}



#' Modify Profile Row Names
#'
#' This function modifies the row names of profile data by converting strand
#' information to no-strand and ensuring consistency between forward and
#' reverse strands.
#'
#' @param profiles A data frame of profile data where row names represent
#' genomic coordinates.
#' @param count_profiles A list containing count profiles for both forward (`+`)
#' and reverse (`-`) strands.
#' @return A data frame with modified row names
#' if the forward and reverse strand lists
#' are identical after strand conversion.
#' If the lists are not identical,
#' a message is printed, and the row names are not modified.
#'
modify_profile_rownames <- function(profiles, count_profiles) {
  plus_converted <- convert_rowname_to_nostrand(rownames(count_profiles$`*`$`+`)) # nolint: line_length_linter.
  minus_converted <- convert_rowname_to_nostrand(rownames(count_profiles$`*`$`-`)) # nolint: line_length_linter.
  if (identical(sort(plus_converted), sort(minus_converted))) {
    message("Both lists are the same after strand conversion.")
    rownames(profiles) <- plus_converted
  } else {
    message("The lists are not the same after strand conversion.")
  }
  return(profiles)
}



#' Combine Plus and Minus Strand Profiles
#'
#' This function combines forward (plus) and reverse (minus) strand count
#' profiles and modifies their row names.
#'
#' @param count_profiles A list containing count profiles for both forward (`+`)
#' and reverse (`-`) strands.
#' @param len_vec An integer specifying the length of the profiles.
#' @return A data frame containing combined profiles with modified row names.
#'
combine_plus_minus_profiles <- function(count_profiles, len_vec) {
  combined_profiles <- cbind(data.frame(count_profiles$`*`$`+`),
                             data.frame(count_profiles$`*`$`-`))
  colnames(combined_profiles) <- c(paste("Plus_", 1:len_vec, sep = ""),
                                   paste("Minus_", 1:len_vec, sep = ""))
  combined_profiles <- modify_profile_rownames(combined_profiles,
                                               count_profiles)
  return(combined_profiles)
}



#' Extract Components from Row Names
#'
#' This function extracts the chromosome, start, end, and strand components 
#' from row names formatted as "chr:start-end;strand".
#'
#' @param row_names_cpn A character vector of row names with each name formatted
#' as "chr:start-end;strand".
#' @return A character vector containing the chromosome, start, end, and strand
#' extracted from the row name.
#'
extract_rowname_components <- function(row_names_cpn) {
  # Split by ':' to separate chromosome and rest
  parts <- strsplit(row_names_cpn, ":")[[1]]
  chr <- parts[1]
  # Split the rest by '-' and ';' to get start, end, and strand
  rest <- strsplit(parts[2], "[-;]")[[1]]
  start <- as.numeric(rest[1])
  end <- as.numeric(rest[2])
  strand <- rest[3]
  return(c(chr, start, end, strand))
}



#' Create GRanges Object from Row Names
#'
#' This function creates a `GRanges` object from row names by extracting
#' the chromosome, start, end, and strand components.
#'
#' @param row_names_str A character vector of row names with each name formatted
#' as "chr:start-end;strand".
#' @return A `GRanges` object created from the extracted components of
#' the rownames.
#'
#' @importFrom IRanges IRanges
#' @importFrom GenomicRanges GRanges
create_granges_from_rownames <- function(row_names_str) {
  # Apply the function to each row name
  components <- t(sapply(row_names_str, extract_rowname_components))
  # Create GRanges object
  gr <- GenomicRanges::GRanges(seqnames = components[, 1],
                               ranges = IRanges::IRanges(start = as.numeric(components[, 2]), # nolint: line_length_linter.
                                                         end = as.numeric(components[, 3])),  # nolint: line_length_linter.
                               strand = components[, 4])
  return(gr)
}



#' Normalized Strand Subtraction
#'
#' This function performs a normalized subtraction between forward (plus) and 
#' reverse (minus) strand signals.
#'
#' @param vec A numeric vector containing the combined forward and reverse 
#' strand signals.
#' @param len_vec An integer specifying the length of the forward strand 
#' signal within `vec`.
#' @return A numeric vector containing the normalized subtraction result of the
#' forward and reverse strand signals.
#'
strands_norm_subtraction <- function(vec, len_vec) {
  p <- as.numeric(vec[1:len_vec])
  m <- as.numeric(vec[(len_vec + 1):(len_vec * 2)])
  # Normalized strand subtraction
  return((p - m) / max(abs(c(p, m))))
}



#' Apply Normalized Strand Subtraction to All Windows
#'
#' This function applies the normalized subtraction between forward (plus) and
#' reverse (minus) strand signals to all windows.
#'
#' @param windows A data frame where each row represents a window containing
#' combined forward and reverse strand signals.
#' @param ext_dis An integer specifying the extension distance,
#' used for adjusting column names.
#' @param len_vec An integer specifying the length of the forward strand signal
#' within each window.
#' @return A data frame containing the normalized subtraction results 
#' for all windows.
#'
strands_norm_subtraction_all <- function(windows, ext_dis, len_vec) {
  #' Apply normalized forward and reverse subtraction to all windows
  #'
  p_min_m_norm_df <- as.data.frame(t(apply(windows, 1,
                                           strands_norm_subtraction, len_vec)))
  pos <- seq(1, ncol(p_min_m_norm_df))
  colnames(p_min_m_norm_df) <- paste0("Pos", pos - ext_dis - 1)
  return(p_min_m_norm_df)
}



#' Wrap up profile for input of the model
#'
#' This function processes multiple columns of
#' data in \code{ctss_rse} and generates
#' count profiles and subtracted normalized profiles,
#' saving them along with metadata
#' as CSV or Parquet files in specified directories.
#'
#' @param ctss_rse SummarizedExperiment object containing count data.
#' @param regions_gr GRanges or GRangesList object specifying genomic regions.
#' @param output_dir Directory where output profiles and metadata will be saved.
#' @param output_dir_name Output directory name within \code{dir_results}.
#' @param output_subdir_name Subdirectory name within \code{outdir_dir_name}
#' where output files will be stored.
#' @param ext_dis Numeric value specifying the extension distance.
#' @param addtn_to_filename Additional text to append to the output file names.
#' @param save_count_profiles Logical value indicating
#' whether to save count profiles.
#' @param file_type Character string indicating the file type for output 
#' ("csv" or "parquet"). Default is "parquet".
#'
#' @details
#' This function iterates through each column of \code{ctss_rse},
#' processes the data to generate count and subtracted normalized profiles,
#' and saves them as CSV or Parquet files.
#' It also creates corresponding metadata files based on
#' row names of the profiles.
#'
#' @importFrom arrow write_parquet
#'
#' @examples
#' \dontrun{
#' # Example usage:
#' wrapup_make_profiles(ctss_rse, regions_gr, dir_results, outdir_dir_name,
#'                      outdir_subdir_name, ext_dis, file_type = "parquet")
#' }
#'
#' @export
wrapup_make_profiles <- function(ctss_rse,
                                 regions_gr,
                                 output_dir,
                                 output_dir_name,
                                 output_subdir_name,
                                 ext_dis,
                                 addtn_to_filename = "",
                                 save_count_profiles = FALSE,
                                 file_type = "parquet") {
  for (i in seq_along(SummarizedExperiment::colnames(ctss_rse))) {

    print(SummarizedExperiment::colnames(ctss_rse)[i])

    current_datetime <- Sys.time()
    formatted_datetime <- format(current_datetime, "%Y-%m-%d %H:%M:%S")
    print(formatted_datetime)

    if (inherits(regions_gr, "GRangesList")) {
      current_region_gr <- regions_gr[[i]]
    } else if (inherits(regions_gr, "GRanges")) {
      current_region_gr <- regions_gr
    } else {
      stop("regions_gr is neither GRanges nor GRangesList")
    }

    ctss_gr <- cast_rse_to_granges(ctss_rse, assay = "counts", coln_assay = i)

    current_region_gr <- convert_strand_to_nostrand_gr(current_region_gr)
    current_region_gr <- remove_metadata_and_duplicates(current_region_gr)

    print("Start making profile")
    count_profiles <- PRIME::heatmapData(current_region_gr, ctss_gr)
    print("Finish making profile")
    rm(current_region_gr, ctss_gr)

    current_datetime <- Sys.time()
    formatted_datetime <- format(current_datetime, "%Y-%m-%d %H:%M:%S")
    print(formatted_datetime)

    len_vec <- ext_dis * 2 + 1

    combined_count_profiles <- combine_plus_minus_profiles(count_profiles, len_vec)
    rm(count_profiles)

    combined_subtnorm_profiles <- strands_norm_subtraction_all(combined_count_profiles, ext_dis, len_vec)

    combined_count_metadata <- create_granges_from_rownames(rownames(combined_count_profiles))
    sum_count <- data.frame(rowSums(combined_count_profiles))
    colnames(sum_count) <- "sum_count"
    combined_count_metadata$sum_count <- sum_count

    # Add rownames as a column before saving
    combined_count_metadata$rownames <- rownames(combined_count_metadata)

    if (file_type == "csv") {
      # Save as CSV without rownames
      utils::write.csv(as.data.frame(combined_count_metadata),
                file = file.path(output_dir,
                                 output_dir_name,
                                 "metadata",
                                 output_subdir_name,
                                 paste0("metadata_count_", output_subdir_name,
                                        addtn_to_filename, "_",
                                        SummarizedExperiment::colnames(ctss_rse)[i], ".csv")),
                row.names = FALSE)
    } else if (file_type == "parquet") {
      # Save as Parquet
      arrow::write_parquet(as.data.frame(combined_count_metadata),
                           file.path(output_dir,
                                     output_dir_name,
                                     "metadata",
                                     output_subdir_name,
                                     paste0("metadata_count_", output_subdir_name,
                                            addtn_to_filename, "_",
                                            SummarizedExperiment::colnames(ctss_rse)[i], ".parquet")))
    }
    rm(combined_count_metadata)

    if (save_count_profiles) {
      combined_count_profiles$rownames <- rownames(combined_count_profiles)

      if (file_type == "csv") {
        # Save as CSV without rownames
        utils::write.csv(as.data.frame(combined_count_profiles),
                  file = file.path(output_dir,
                                   output_dir_name,
                                   "profiles",
                                   output_subdir_name,
                                   paste0("profiles_count_", output_subdir_name,
                                          addtn_to_filename, "_",
                                          SummarizedExperiment::colnames(ctss_rse)[i], ".csv")),
                  row.names = FALSE)
      } else if (file_type == "parquet") {
        # Save as Parquet
        arrow::write_parquet(as.data.frame(combined_count_profiles),
                             file.path(output_dir,
                                       output_dir_name,
                                       "profiles",
                                       output_subdir_name,
                                       paste0("profiles_count_", output_subdir_name,
                                              addtn_to_filename, "_",
                                              SummarizedExperiment::colnames(ctss_rse)[i], ".parquet")))
      }
    }
    rm(combined_count_profiles)

    combined_subtnorm_profiles$rownames <- rownames(combined_subtnorm_profiles)

    if (file_type == "csv") {
      # Save as CSV without rownames
      utils::write.csv(as.data.frame(combined_subtnorm_profiles),
                file = file.path(output_dir,
                                 output_dir_name,
                                 "profiles_subtnorm",
                                 output_subdir_name,
                                 paste0("profiles_subtnorm_", output_subdir_name,
                                        addtn_to_filename, "_",
                                        SummarizedExperiment::colnames(ctss_rse)[i], ".csv")),
                row.names = FALSE)
    } else if (file_type == "parquet") {
      # Save as Parquet
      arrow::write_parquet(as.data.frame(combined_subtnorm_profiles),
                           file.path(output_dir,
                                     output_dir_name,
                                     "profiles_subtnorm",
                                     output_subdir_name,
                                     paste0("profiles_subtnorm_", output_subdir_name,
                                            addtn_to_filename, "_",
                                            SummarizedExperiment::colnames(ctss_rse)[i], ".parquet")))
    }
    rm(combined_subtnorm_profiles)

    gc()

    current_datetime <- Sys.time()
    formatted_datetime <- format(current_datetime, "%Y-%m-%d %H:%M:%S")
    print(current_datetime)
  }
}



#' Prepare Directory Structure for Profile Output
#'
#' This function sets up a directory structure for storing profile output data.
#' It creates a main output directory along with several subdirectories for
#' different types of profile data. If the specified main output directory
#' already exists, the function will not recreate it or its subdirectories.
#'
#' @param output_dir A character string specifying the path to the base
#'   directory where the output structure will be created. Defaults to the
#'   current directory (".").
#' @param output_dir_name A character string specifying the name of the main
#'   output directory. Defaults to "profile_output".
#' @param output_main_name A character vector specifying the names of the main
#'   subdirectories to be created within the main output directory. Defaults to
#'   c("metadata", "profiles", "profiles_subtnorm", "predictions").
#' @param output_subdir_name A character vector specifying the names of the
#'   subdirectories to be created within each main subdirectory. Defaults to
#'   c("pos", "neg").
#' @return This function does not return any value. It creates the specified
#'   directory structure on the file system.
#' @examples
#' # Example usage:
#' # Prepare a profile output directory with default settings
#' prep_profile_dir()
#'
#' # Prepare a profile output directory with custom settings
#' prep_profile_dir(output_dir = "results", output_dir_name = "custom_output")
#' @export
prep_profile_dir <- function(output_dir = ".",
                             output_dir_name = "profile_output",
                             output_main_name = c("metadata",
                                                  "profiles",
                                                  "profiles_subtnorm",
                                                  "predictions"),
                             output_subdir_name = c("pos", "neg")) {

  # Create the output dir and main dir
  new_path <- file.path(output_dir, output_dir_name)

  if (!file.exists(new_path)) {
    dir.create(new_path)

    # Create main directories and their subdirectories
    lapply(output_main_name, function(main) {
      main_path <- file.path(new_path, main)
      dir.create(main_path)

      if (length(output_subdir_name) > 0) {
        lapply(output_subdir_name, function(subdir) {
          subdir_path <- file.path(main_path, subdir)
          dir.create(subdir_path)
        })
      }
    })

    cat("New folder created:", new_path, "\n")
  } else {
    cat("Folder already exists:", new_path, "\n")
  }
}






#' Convert SummarizedExperiment to GRanges with Assay Data
#'
#' This function converts a `SummarizedExperiment` object to a `GRanges` object
#' and adds a specified assay data column to the resulting `GRanges` object.
#'
#' @param rse A `SummarizedExperiment` object containing the genomic ranges and
#'   assay data.
#' @param assay A character string specifying the assay name to extract from
#'   the `SummarizedExperiment` object. Default is "counts".
#' @param coln_assay An integer specifying the column index of the assay to use.
#'   Default is 1.
#' @param colname A character string specifying the name of the column to be
#'   added to the `GRanges` object. Default is "score".
#' @return A `GRanges` object with the specified assay data added as a metadata
#'   column.
#' @importFrom SummarizedExperiment rowRanges assay
#' @importFrom GenomicRanges GRanges mcols
#' @importFrom magrittr %>%
#' @export
#' @examples
#' # Example usage:
#' # rse is a SummarizedExperiment object
#' gr <- cast_rse_to_granges(rse, assay = "counts",
#'                           coln_assay = 1, colname = "score")
cast_rse_to_granges <- function(rse,
                                assay = "counts",
                                coln_assay = 1,
                                colname = "score") {
  # Extract the row ranges from the SummarizedExperiment object
  gr <- SummarizedExperiment::rowRanges(rse) %>% GenomicRanges::GRanges() # nolint: pipe_operator_linter

  # Extract the assay data
  assay_data <- SummarizedExperiment::assay(rse, assay)

  # Assign the assay data to the specified column name in the GRanges object
  GenomicRanges::mcols(gr)[[colname]] <- assay_data[, coln_assay]

  return(gr)
}


#' Convert Strand Information to No Strand for GRanges Object
#'
#' This function takes a `GRanges` object
#' and sets the strand information to `"*"`,
#' indicating no strand specificity.
#'
#' @param region_gr A `GRanges` object containing genomic ranges.
#'
#' @return A `GRanges` object with the strand information set to `"*"`.
#'
#' @details The function modifies the strand information
#' of the input `GRanges` object, setting it to `"*"`.
#' This is useful in situations where strand information
#' is irrelevant or not needed.
#'
#' @importFrom GenomicRanges strand
#' @export
convert_strand_to_nostrand_gr <- function(region_gr) {
  GenomicRanges::strand(region_gr) <- "*"
  return(region_gr)
}


#' Remove Metadata and Duplicate Genomic Ranges
#'
#' This function takes a `GRanges` object, removes all metadata,
#' and then eliminates duplicate genomic ranges based on sequence names,
#' start and end positions, and strand information.
#'
#' @param gr A `GRanges` object containing genomic ranges
#' with or without metadata.
#'
#' @return A `GRanges` object without any metadata and
#' without duplicate genomic ranges.
#'
#' @details The function will strip the input `GRanges` object
#' of all metadata columns and then identify
#' and remove duplicate genomic ranges.
#' Only the `seqnames`, `ranges`, and `strand` information
#' will be considered for identifying duplicates.
#'
#' @examples
#' # Create a GRanges object with metadata
#' gr <- GenomicRanges::GRanges(
#'     seqnames = c("chr1", "chr1", "chr2", "chr2", "chr3", "chr3"),
#'     ranges = IRanges::IRanges(start = c(100, 100, 200, 250, 300, 300),
#'                               end = c(150, 150, 250, 250, 350, 350)),
#'     strand = c("+", "+", "-", "-", "+", "+"),
#'     score = c(5.0, 5.0, 4.0, 4.0, 3.0, 3.0)  # Example metadata
#' )
#'
#' # Remove metadata and duplicate genomic ranges
#' unique_gr <- remove_metadata_and_duplicates(gr)
#'
#' # Inspect the result
#' unique_gr
#'
#' @importFrom GenomicRanges GRanges seqnames ranges strand start end duplicated
#' @importFrom IRanges IRanges
#' @export
remove_metadata_and_duplicates <- function(gr) {
  # Remove metadata columns by creating a new GRanges object without metadata
  gr_no_metadata <- GenomicRanges::GRanges(
    seqnames = GenomicRanges::seqnames(gr),
    ranges = IRanges::IRanges(start = GenomicRanges::start(gr),
                              end = GenomicRanges::end(gr)),
    strand = GenomicRanges::strand(gr)
  )

  # Identify duplicated ranges based on seqnames, ranges, and strand
  duplicated_indices <- GenomicRanges::duplicated(gr_no_metadata)

  # Subset the GRanges object to keep only unique ranges
  unique_gr <- gr_no_metadata[!duplicated_indices]

  return(unique_gr)
}



#' Extend Genomic Ranges from the Center Based on Thickness
#'
#' This function extends genomic ranges from their center points, defined by
#' the "thick" positions in the metadata columns of a `GRanges` object. The
#' "thick" column must exist and be of class `IRanges`. The extension can
#' either maintain the original interval lengths or allow them to vary.
#'
#' @param gr A `GRanges` object containing genomic ranges with a "thick" column
#'   in the metadata.
#' @param dis A numeric value specifying the distance to extend from the center.
#' @param keep_same_length A logical value indicating whether to keep the
#'   intervals at the same length after extension. Defaults to TRUE.
#' @return A `GRanges` object with updated start and end positions, and an
#'   updated "thick" column if `keep_same_length` is TRUE.
#' @importFrom IRanges IRanges
#' @importFrom S4Vectors mcols
#' @examples
#' # Assuming `gr` is a GRanges object with a 'thick' column of class IRanges
#' extended_gr <- extend_from_center_thick_gr(gr, dis = 100, keep_same_length = TRUE) # nolint: line_length_linter.
#' @export
extend_from_center_thick_gr <- function(gr,
                                        dis,
                                        keep_same_length = TRUE) {

  # Check if the thick column exists in the metadata
  if (!("thick" %in% names(S4Vectors::mcols(gr)))) {
    stop("The 'thick' column must exist in the metadata columns.")
  }

  # Check if the thick column is of class IRanges
  if (!inherits(S4Vectors::mcols(gr)$thick, "IRanges")) {
    stop("The 'thick' column must be of class IRanges.")
  }

  # If both checks pass, print a success message
  print("The 'thick' column exists and is of class IRanges.")

  start(gr) <- pmax(start(gr$thick) - dis, 1)

  if (keep_same_length) {
    end(gr) <- start(gr) + (dis * 2)
    mcols(gr)$thick <- IRanges::IRanges(start = start(gr) + dis,
                                        end = start(gr) + dis)
    print("If the extended start is out-of-range, the thick will be rewritten to the center of the extended negative range.") # nolint: line_length_linter.
  } else {
    end(gr) <- start(gr$thick) + dis
    print("The length of the intervals could be different. If you want to keep the same length, set 'keep_same_length = TRUE'.") # nolint: line_length_linter.
  }

  return(gr)
}


#' Remove 'chrM' from GRangesList
#'
#' This function removes all genomic ranges located on the chromosome 'chrM'
#' from each `GRanges` object within a `GRangesList`. It is useful for excluding
#' mitochondrial DNA, which is often represented by 'chrM', from analyses.
#'
#' @param grl A `GRangesList` object containing genomic ranges.
#' @return A `GRangesList` object with all ranges on 'chrM' removed.
#' @importFrom GenomicRanges GRangesList seqnames
#' @importFrom S4Vectors Rle
#' @examples
#' library(GenomicRanges)
#' gr1 <- GRanges(seqnames = c("chr1", "chrM", "chr2"), 
#'                ranges = IRanges(start = 1:3, width = 3), strand = "+")
#' gr2 <- GRanges(seqnames = c("chrM", "chr2", "chr3"), 
#'                ranges = IRanges(start = 4:6, width = 3), strand = "-")
#' grl <- GRangesList(gr1 = gr1, gr2 = gr2)
#'
#' # Remove 'chrM' ranges
#' modified_grl <- drop_chrM_from_grl(grl)
#' @export
drop_chrM_from_grl <- function(grl) {
  modified_grl <- lapply(grl, function(gr) {
    gr <- gr[seqnames(gr) != "chrM"]
    return(gr)
  })
  return(GenomicRanges::GRangesList(modified_grl))
}


#' Run the PRIMEloci Workflow
#'
#' This function encapsulates the entire PRIMEloci workflow,
#' including creating profiles, running a Python script for profile prediction,
#' and processing the results into a `GRangesList`.
#'
#' @param ctss_rse A `SummarizedExperiment` object containing CTSS data.
#' @param tc_grl A `GRangesList` object containing TC data.
#' @param config_file Character. Path to the configuration file in YAML format.
#' Default is "config_R_PRIMEloci.yaml".
#'
#' @return A `GRangesList` containing the processed results.
#'
#' @details
#' This function orchestrates the PRIMEloci workflow, including:
#' - Setting up necessary directories based on the configuration file.
#' - Creating profiles using the CTSS and TC data.
#' - Running a Python script for predicting profile probabilities.
#' - Processing the output files and returning a `GRangesList` object.
#'
#' The workflow relies on configuration parameters specified in a YAML file.
#'
#' @importFrom yaml read_yaml
#' @importFrom tools file_path_sans_ext
#' @importFrom assertthat assert_that
#' @importFrom data.table fread fwrite
#' @importFrom argparse ArgumentParser
#' @importFrom foreach foreach %dopar%
#' @importFrom doParallel registerDoParallel stopImplicitCluster
#' @importFrom parallel detectCores
#' @importFrom GenomicRanges GRangesList sort
#' @importFrom rtracklayer import
#' @importFrom reticulate py_run_string
#'
#' @examples
#' \dontrun{
#' ctss_rse <- loadRDS("path_to_ctss_rse.rds")
#' tc_grl <- loadRDS("path_to_tc_grl.rds")
#' gr_list <- run_PRIMEloci(
#'   ctss_rse = ctss_rse,
#'   tc_grl = tc_grl,
#'   config_file = "config_PRIMEloci.yaml"
#' )
#' }
#' @export
run_PRIMEloci <- function(ctss_rse) {

  tmp_dir <- tempdir()
  dir.create(tmp_dir)

  # Default configuration
  config <- list(
  output_dir = tmp_dir,
  profile_main_dir = "profiles",
  python_script_dir = system.file("python", package = "PRIME"),
  model_path = system.file("models", "PRIMEloci_GM12878_wt10M.sav", package = "PRIME"),
  prefix_out_name = "modelPred",
  profile_sub_dir = "tcs",
  profile_file_type = "parquet",
  threshold = 0.2,
  save_count_profiles = TRUE,
  ext_dis = 200,
  partial_name = "pred_slt.*\\.bed"
)

  # Set up directories and file paths based on config
  prediction_dir <- file.path(config$output_dir,
                              config$profile_main_dir,
                              "predictions",
                              config$profile_sub_dir)
  outdir_main_name <- c("metadata",
                        "profiles",
                        "profiles_subtnorm",
                        "predictions")
  outdir_subdir_name <- config$profile_sub_dir

  # Create output directories
  prep_profile_dir(output_dir = config$output_dir,
                   output_dir_name = config$profile_main_dir,
                   output_main_name = outdir_main_name,
                   output_subdir_name = outdir_subdir_name)

  # Call tag clusters
  writeLines(paste0("\nExtracting TCs from ", substitute(ctss_rse), ".."))
  tc_grl <- suppressWarnings(get_tcs_and_extend_fromthick(ctss_rse, ext_dis=config$ext_dis))

  # Create profiles for the specified subdir_name
  writeLines(paste0("\nCreating profiles for ", outdir_subdir_name, ".."))
  wrapup_make_profiles(ctss_rse,
                       tc_grl,
                       config$output_dir,
                       config$profile_main_dir,
                       outdir_subdir_name,
                       config$ext_dis,
                       save_count_profiles = config$save_count_profiles, # nolint: line_length_linter.
                       file_type = config$profile_file_type)

  writeLines("\n### Finished profile creation ###\n")

  # Run Python script for profile prediction
  run_prediction_python_script(
    script_path = system.file("python","_predict_profile_probabilities.py", package = "PRIME"),
    script_dir = config$python_script_dir,
    profile_main_dir = file.path(config$output_dir, config$profile_main_dir),
    profile_sub_dir = config$profile_sub_dir,
    model_path = config$model_path,
    name_prefix = config$prefix_out_name,
    threshold = config$threshold,
    file_format = config$profile_file_type
  )

  # Call the main function with the parsed argument
  gr_list <- process_all_files(prediction_dir, config$partial_name)

  #Remove temporary files
  unlink(tmp_dir,recursive=TRUE)

  writeLines("Done!")

  return(gr_list)
}



#' Get Highest Non-Overlapping Ranges for a Chromosome
#'
#' This function takes a GenomicRanges::GRanges object
#' and returns the highest non-overlapping ranges
#' based on the scores in the metadata column.
#'
#' @param gr A GenomicRanges::GRanges object with a 'score' metadata column.
#' @return A GenomicRanges::GRanges object with
#' the highest non-overlapping ranges.
#' @import GenomicRanges
#' @import IRanges
#' @export
get_highest_non_overlap_chr <- function(gr) {

  gr <- GenomicRanges::sort(gr, by = ~score, decreasing = TRUE)
  result <- GenomicRanges::GRanges()

  while (length(gr) > 0) {
    highest <- gr[1]
    result <- c(result, highest)
    gr <- gr[!IRanges::overlapsAny(gr, highest)]
  }

  return(result)

}

#' Get Highest Non-Overlapping Ranges for All Chromosomes in Parallel
#'
#' This function takes a `GenomicRanges::GRanges` object and returns the highest 
#' non-overlapping ranges for all chromosomes, processed in parallel.
#'
#' The function splits the input `GRanges` object by chromosome and then 
#' processes each chromosome in parallel to find the highest non-overlapping 
#' ranges based on the 'score' metadata column. The results from each 
#' chromosome are then combined and sorted.
#'
#' @param gr A `GenomicRanges::GRanges` object with a 'score' metadata column.
#' @param num_cores The number of cores to use for parallel processing. 
#' Default is `parallel::detectCores() - 1`.
#'
#' @return A `GenomicRanges::GRanges` object with the highest non-overlapping 
#' ranges for all chromosomes.
#'
#' @import GenomicRanges
#' @import foreach
#' @import doParallel
#' @import parallel
#' @export
get_highest_non_overlap <- function(gr,
                                    num_cores = parallel::detectCores() - 1) {

  gr_list <- GenomicRanges::split(gr, GenomicRanges::seqnames(gr))

  doParallel::registerDoParallel(cores = num_cores)

  i <- NA ## avoid warning
  results <- foreach::foreach(i = seq_along(gr_list), .combine = c) %dopar% {
    get_highest_non_overlap_chr(gr_list[[i]])
  }

  doParallel::stopImplicitCluster()

  results <- GenomicRanges::sort(results, by = ~start)

  return(results)

}


#' Process a BED file and save the highest non-overlapping ranges
#'
#' This function loads a BED file, converts it to a `GRanges` object, and selects the highest
#' non-overlapping ranges using the `get_highest_non_overlap` function. The results are saved
#' as both RDS and BED files.
#'
#' @param input_bed Character. The path to the input BED file.
#' @param output_dir Character. The directory where the output files will be saved.
#'
#' @return A `GRanges` object containing the highest non-overlapping ranges.
#'
#' @importFrom tools file_path_sans_ext
#' @importFrom GenomicRanges sort
#' @export
wrapup_filter_bed_to_reduce <- function(input_bed, output_dir = NULL) {
  # Load the bed file and create GRanges object
  bed_file <- load_bed_file(input_bed)
  gr <- create_granges_from_bed(bed_file)

  # Inform the user that processing is starting
  writeLines("Starting to get highest non-overlapping ranges...")
  writeLines("It may take a while depending on the size of the input file...")
  start_time <- Sys.time()
  print(start_time)

  # Get the highest non-overlapping ranges
  selected_gr <- get_highest_non_overlap(gr)
  selected_gr <- GenomicRanges::sort(selected_gr)
  end_time <- Sys.time()
  print(end_time - start_time)

  # If output_dir is specified, save the GRanges object to the directory
  if (!is.null(output_dir) && output_dir != FALSE) {
    input_basename <- tools::file_path_sans_ext(basename(input_bed))
    save_granges_to_bed(selected_gr, output_dir, input_basename, bed_file)
  }

  writeLines("Done!")

  # Return the selected GRanges object
  return(selected_gr)
}



#' Load a BED file and validate its columns
#'
#' This function reads a BED file into a `data.table` and checks that it contains
#' the required columns: 'chrom', 'chromStart', 'chromEnd', 'strand', and 'score'.
#'
#' @param input_bed Character. The path to the input BED file.
#'
#' @return A `data.table` containing the BED file data.
#'
#' @importFrom data.table fread
#' @importFrom assertthat assert_that
#' @export
load_bed_file <- function(input_bed) {
  bed_file <- utils::read.table(input_bed, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
  required_cols <- c("chrom", "chromStart", "chromEnd", "strand", "score")
  assertthat::assert_that(all(required_cols %in% colnames(bed_file)),
                          msg = "The BED file must contain 'chrom', 'chromStart', 'chromEnd', 'strand', and 'score' columns.")
  return(bed_file)
}

#' Create a GRanges object from a BED data.table
#'
#' This function converts a `data.table` containing BED file data into a `GRanges` object.
#' The required columns are extracted and used to define the `GRanges` object, and the remaining
#' columns are added as metadata.
#'
#' @param bed_file A `data.table` containing the BED file data.
#'
#' @return A `GRanges` object.
#'
#' @importFrom GenomicRanges GRanges
#' @importFrom IRanges IRanges
#' @importFrom S4Vectors mcols
#' @export
create_granges_from_bed <- function(bed_file) {
  gr <- GenomicRanges::GRanges(seqnames = bed_file$chrom,
                               ranges = IRanges::IRanges(start = bed_file$chromStart + 1,
                                                         end = bed_file$chromEnd),
                               strand = bed_file$strand)
  S4Vectors::mcols(gr) <- bed_file[, !(names(bed_file) %in% c("chrom", "chromStart", "chromEnd", "strand"))]
  return(gr)
}

#' Save a GRanges object to RDS and BED formats
#'
#' This function saves a `GRanges` object as an RDS file and converts it to a `data.frame`
#' for saving as a BED file. The BED file is saved with adjusted columns to match the original format.
#'
#' @param gr A `GRanges` object to be saved.
#' @param output_dir Character. The directory where the output files will be saved.
#' @param input_basename Character. The base name for the output files.
#'
#' @return None. The function saves the output files to the specified directory.
#'
#' @importFrom tools file_path_sans_ext
#' @importFrom data.table fwrite
#' @importFrom S4Vectors mcols
#' @export
save_granges_to_bed <- function(gr, output_dir, input_basename, bed_file) {
  # Save the selected GRanges object to an RDS file
  output_rds <- file.path(output_dir, paste0(input_basename, "_reduced.rds"))
  saveRDS(gr, file = output_rds)
  cat("Reduced GRanges object saved to", output_rds, "\n")

  # Convert GRanges object to a data frame
  bed_df <- as.data.frame(gr)

  # Select and rearrange the columns
  bed_df <- bed_df[, c("seqnames", "start", "end", "width", "strand", colnames(S4Vectors::mcols(gr)))]

  # Adjust the 'start' column to be 0-based by subtracting 1
  bed_df$start <- bed_df$start - 1

  # Rename the columns to match BED file format
  data.table::setnames(bed_df, c("seqnames", "start", "end", "strand"), c("chrom", "chromStart", "chromEnd", "strand"))

  # Rearrange the columns to match the original BED file format
  bed_df <- bed_df[, colnames(bed_file)]

  # Sort the data frame by chrom and chromStart
  bed_df <- bed_df[order(bed_df$chrom, bed_df$chromStart), ]

  # Write to BED file
  output_bed <- file.path(output_dir, paste0(input_basename, "_reduced.bed"))
  data.table::fwrite(bed_df, file = output_bed, sep = "\t", quote = FALSE, col.names = TRUE)

  cat("Reduced GRanges object saved to", output_bed, "\n")
}